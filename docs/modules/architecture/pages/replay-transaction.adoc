= Transaction Replay. [[replay_transaction]]

The Transaction-Replaying helps to re-invoke the transaction that stopped due to
xref:replay-transaction.adoc#resource-unavailable[resource-unavailable] issues.
It guarantees eventual consistency of the entire task.

[[resource-unavailable]]
====
*Resource-Unavailable* term in the Microservice Architecture

In microservice architecture, a *"resource-unavailable"* issue typically refers to a situation where one microservice is unable to access a necessary resource.
This resource could be another microservice, a database, a third-party API, or any other external system or service that the microservice depends on.
====

If a sub-task is failed due to Resource Unavailable, it can be retried most of the time instead of stopping the task with en exception in microservice environment.
Because you know that giving up the task due to an exception is not easy in microservice environment like in a standalone application with a single database. it may cause to data inconsistency most of the time due to one task consist of multiple sub-tasks (multiple atomic transactions).
If one of atomic transactions is failed, other all atomic transactions that have been successfully executed so far should be state back (undo).

If there is an exception while the executing main consideration is that we should identify the exception type.
Whether the exception is *Resource Unavailable* or not. if the execution is a *Resource Unavailable* exception it will be resolved soon and then the execution can execute successfully.
As mentioned above if we can identify the exception as a *Resource Unavailable* exception we can wait some time and re-invoke the executions.
Replaying tasks (transactions/operations) helps to have the eventual consistency without giving up the transaction.

For identifying the exceptions as a retryable or not, it is used xref:framework:non_retryable_executor_exception.adoc[NonRetryableExecutorException] and xref:framework:retryable_executor_exception.adoc[RetryableExecutorException].
If the executor throws and `RetryableExecutorException` the saga engine keep the transaction in the event-store for retrying.

[[ephemeral]]
====
*Ephemeral* behavior of the instances.

In the context of microservices, ephemeral refers to the principle that a microservice can be created, destroyed, and replenished on-demand on a target easily, quickly, and with no side effects.
====

== StackSaga Agent

Stacksaga agent is the application that invokes for retrying the transactions.
You already know that if the transaction is failed with a network exception (*Resource Unavailable*) the transaction can be retired.
That retrying part is done by the Stacksaga agent service.

=== Retrying Transactions with StackSaga Agent

You know that the transactions are executed by the StackSaga framework.
If the transaction is not able to process due to some *Resource Unavailable* exception, the transaction is kept in the event-store for retrying.
for instance, while make-order process an exception is occurred in the MakePaymentExecutor due to the payment-services are not available for some reason.
then order-service saves the transaction with the help of StackSaga framework in the event-store for retrying.
With the given configurations the agent application trigger the schedulers for gathering the transaction that should be retried.
The transactions that are eligible for retrying are caught by the agent and the agent distributes the transactions for the available instances for retrying.

====
[[why-instance-does-not-involve-directly-for-retrying]]
IMPORTANT: Sometimes you might think that why can't be re-invoked the transactions by the own instance without an agent? +
The short answer is it can't be done due the instances are xref:replay-transaction.adoc#ephemeral[Ephemeral] in nature in the microservice architecture. +
For instance, just imagine there are 10 instances running on, and there are 100 transactions have been saved temporarily by them due to some network issues.
After a while, the scheduler is triggered for replying the transactions on each instance.
At that moment it can have different instances count due to scaling up or scaling down based on the load.
Just imagine there was an instance called "a" that made some retryable transactions before triggering the scheduler, and that instance might not be running when the scheduler is triggered for retrying.
Then the transactions that made by the instance called "a" cannot be run ever.
(Because the instance is identified with a random generated id and the transaction is stored with that instance id when the transaction is initiated).
Then some transactions can be missing.
This is one of the major reasons that replaying cannot involve all available instances at the same time.

In the below diagram you can see there are 7 translations that should be exposed for retrying that have been run by 3 instances.
but the problem is when the scheduler is triggered for retrying in each instance, only 2 instances are being running called *instance:3491465* and *instance:3491425*. the *instance:3400001* was destroyed. then that transaction can not be exposed for retrying.

image:stacksaga-diagram-transaction-direct-retry-by-instance.drawio.svg[alt="why instance does not involve directly for retrying in StackSaga"]
====

Here you can see how the StackSaga Agent involves and distributes the transactions within available instances in high-level.

image:stacksaga-diagram-how-stacksaga-agent-distribute-transactions.drawio.svg[alt="how stacksaga agent distribute transactions"]

Here you can see it does not matter which instance initiated the transaction. all the transaction that should be retried are scanned by the agent and those are distributed with the available services.
The communication happens via the In-built Http endpoints that has been provided by `stacksaga-spring-boot-starter`.

== StackSaga agent deployment in Cloud environment

You know that if we are in the cloud environment we have to make our deployment by adapting to the geographically distributed system.
Then we mainly deal with *regions* and *zones*.
In stacksaga ecosystem, it is very important for identifying the distributed deployments geographically to enhance the performance and balance the load between the target nodes.
You can deploy the StackSaga Agents in tow was based on the geographical distribution.

=== Regional Agent Architecture

The StackSaga agent works for only one region by default.
For instance, if your `order-service` has been deployed in multiple regions called `region-1` and `region-2`, you have to deploy tow StackSaga-agent services for both `region-1` and `region-2` separately.

image:stacksaga-diagram-stacksaga-agent-default-deployment-in-cloud-env-with-multiple-db-replications.drawio.svg[alt="stacksaga agent default deployment in cloud environment"]

<1> Fetches the transactions that should be retried from the event-store based on the particular region that the agent instance running on and add to the queue for sharing for retrying.

<2> distribute the transactions for the available instances in the same region.

In general, if the system is a large one, the database is replicated based on the region like in the diagram.
even the database has not been replicated physically StackSaga agent fetched the transactions related to the region like below.

image:stacksaga-diagram-stacksaga-agent-default-deployment-in-cloud-env-with-one-db.drawio.svg[alt="how stacksaga agent distribute transactions"]

=== Zonal Agent Architecture

If you want to have the agent for each zone instead of region, it is also supported.
you know that StackSaga service agent support both eureka service registry and Kubernetes service registry environments.
if you in eureka based service discovery when the system getting bigger with adding more and more services to the cluster sometimes you have to move to Zonal Isolation to Reduced Network Latency.
For instance just imagine when the system is started there ware 10 microservices and deployed 15 instances for each in one region.

|===
|Header 1 |Header 2 |Header 3

|Column 1, row 1
|Column 2, row 1
|Column 3, row 1

|Column 1, row 2
|Column 2, row 2
|Column 3, row 2

|Column 1, row 3
|Column 2, row 3
|Column 3, row 3
|===

== Master and Slaves architecture for retrying

This method refers to electing a leader (Master instance) withing the available instances.
For instance, there can have 10 instances in your cluster for *order-service*.
StackSaga framework has to select one of them as the leader for executing the retrying.
This is where the leader-election comes into the picture.

image:stacksaga-diagram-master-slaves-leader-election.drawio.svg[alt="stacksaga diagram master slaves leader election"]

In The above diagram, it has been mentioned 2 regions.
Transactions replaying is done based on the regional metadata.
A leader is appointed for one region.
That means in a region can have only one leader.
If you have deployed applications in many regions, each region will have one leader.

How is the transaction replaying done?
First of all, let's have an understanding what metadata is saved with the transaction in the event store.

All the transactions are saved in the event-store with the following data.

* Instance id: the instance that the transaction was initialized.
* Region: the region that instance was located
* Zone: the zone that instance was located
* serviceName: the name of the service

NOTE: You can see all the above metadata in the dashboard.

Due to keeping the transaction with the region data, the engine can determine which leader should access which transactions.
If the transaction was initiated in region-1 the transaction will be exposed to the region-1's leader.

Electing the leader is done based on your environment.

== Service-Agent and Slaves architecture for retrying

Service agent architecture refers to having a desperate service for doing the replay instead of selecting one of available instances like master and slaves architecture.

image:stacksaga-diagram-agent-slaves-leader-election.drawio.svg[alt="stacksaga diagram agent slaves leader election"]

NOTE: In this way, the retry dependencies shouldn't be added to the applications.
Instead of that, just run the *saga-service-agent* standalone application by mentioning the target service name(s).

Service agent architecture can be used in 2 ways.

. Agent for service

Your system can have multiple servers like order service, delivery service, customer service and so on.
From those services, some of them have Stacksaga implemented on it.
Just imagine the order service and delivery service use Stacksaga.
So then those services should have agents for process replaying.
We can deploy 2 agent services separately called order-service-agent and *delivery-service-agent*.
In this way, the relationship between the service and the agent is one to one.

image:stacksaga-diagram-seperate-agent-leader-election.drawio.svg[alt="stacksaga diagram seperate agent leader election"]

Here you can see the order-service and delivery-service has separate services called *order-service-agent* and *delivery-service-agent*.

. Agent for services

Instead of having separate service agents, it's delayed a single service for many services.
The relationship between the agent and service is *one-to-many*.
One agent can have many services connected ro retrying.

image:stacksaga-diagram-public-agent-leader-election.drawio.svg[alt="stacksaga diagram public agent leader election"]

IMPORTANT: *Agent for services* can be used only if you use a single xref:event_store.adoc[even-store] for the services that are connected to the agent service.
The reason is only one event-store can be configured into the agent service.
For instance, if you want to deploy a single service age for both order-service and delivery-service, both services should use the same event-store.
Refer the xref:event_store.adoc[even-store] to see the ways that you can use event-store.

== Filtering Retryable transactions from the event-store.

You know already that the replay process is done by running schedulers.
When the scheduler is triggered, the master node fetches the transactions that should be retried from the event-store.

When filtering the retryable transactions, the following things are considered.

. Region: The transactions are filtered for the region of the master instance.
. Transaction status: The transaction status should be *reverting* or *processing*
. xref:replay-transaction.adoc#transaction_lifetime[Transaction Lifetime]
. xref:replay-transaction.adoc#transaction_leisure_time[Transaction Leisure time]
. xref:replay-transaction.adoc#transaction_restore_retention_time[Transaction Restore Retention Time]

[[transaction_lifetime]]
== Transaction Lifetime

All the transactions are retried within a specific duration that you configured.
After the time duration that transactions are expired, It ensures not accumulating the transactions that cannot be invoked successfully after invoking many times.

TIP: In the admin dashboard, you can see the expired transactions.
And also after fixing the issue, you can extend the time for exposing to the retrying process again.

In the below, you can see it with diagram.
The transaction is initiated at the first after initialization the transaction can be exposed to the schedulers withing the specific time period.
After the time period, the transaction is not exposed to re-invoking.

image:stacksaga-diagram-transaction-retry-life-time.drawio.svg[alt="stacksaga diagram transaction retry life time"]

[[transaction_leisure_time]]
== Transaction Leisure time

After exposing the transaction to be retried, the transaction is shared to one of available instances immediately to execute.
After the executing by that particular instance, if the transaction is failed again due to a network issues, the transaction can be exposed to the same scheduler nearly. +
There is no point in executing the transaction again and again within a small amount of time while the target service is unavailable. +
You can configure how long time a transaction should be kept at leisure without exposing to the scheduler.
That time is called as Transaction Leisure time.

In the below, you can see it with diagram.
After initiating the transaction, the transaction has been exposed to retrying if the transaction is failed due to resource-unattainable issue.
After exposing the transaction, the transaction is frozen for a while (based on your configuration) as leisure time.
While that time, no one can access the data for retrying.
After the end of that leisure time, the transaction is exposed for replaying if the transaction is still one of running status (processing or reverting).

image:stacksaga-diagram-retry-leisure-time.drawio.svg[alt="stacksaga diagram retry leisure time"]

[[transaction_restore_retention_time]]
== Transaction Restore Retention Time

How long the transaction should be kept waiting to determine whether the transaction unexpectedly crashed.
The value should be in hours.
If there are some transactions in the event-store that have been shared for replaying but even after 12-hours (configured time,) that transaction has not been retried with that token.
This is a very rare case.
For instance, after receiving the transaction for replaying by the one of available instances, the instance goes down due to a power cut without executing the transaction.
But the leader has been updated as the transaction has been shared to an instance for doing replay.
Due to that, the leader doesn't invoke those transactions again until the transaction is updated by the received instance or the `crashedTransactionRestoreRetentionHours` is exceeded.
Before collecting the transactions that should be retried, the leader checks that if there are some transactions that exceed the `crashedTransactionRestoreRetentionHours` time and those transactions update again as to be eligible for retrying.

image:stacksaga-diagram-tx-retry-stucked-retention.drawio.svg[alt="stacksaga diagram tx retry stucked retention"]

*What happens if a transaction is retried after being declared as crashed?*

That means that due to the retention time is exceeded, the engine decides to expose the transaction for retrying.
Then the transaction will be shared to one of the available instances. +
While then that instance which received the transaction for retrying previously (before the latest expose) invokes the transaction accidentally.

Just imagine the instance has been stuck for 10 hours due to memory issues or kind of situation. +
After 10 hours the that transaction will be executed by the instance that was stuck.

Then there are two situations can be happened.

1. The transaction can be still in the replying status (even though exposed many times after the retention time.
2. The transaction already executed successfully.
(By using other instance(s).

In the first scenario, you may think that the transaction can be executed two times.
Because the old instance again has started to execute the collected transaction to the queue.
And the transaction can be in another instance's queue for executing due to the engine exposed the transaction for retrying after exceeding in the retention time.
Even though There is a one-in-a-billion chance of that happening, it is not invoked two times at all.

Because along with every retry notification, a toke is passed when the execution is shared.
The token number is an integer number that increased one by one every time the transaction is exposed for retrying.

In our case, the old instance's queue can have a less number for the retry notification event than the new instance's queue has.
Therefore, the engine will allow only the token that recently issued.
Then the old transaction is rejected executing.
The diagram shows how it works.
Here you can see that only the execution that contains the latest value is executed (the latest token should be the same as the value in the event-store).
Any other executions are rejected.

image:stacksaga-diagram-retry-leisure-time-crash.drawio.svg[alt="stacksaga diagram retry leisure time crash"]

////

The following reasons are caused to Transaction Replay.

. IF the transaction executor was failed with <<NonRetryableExecutorException,NonRetryableExecutorException>>. +
Any <<executor_architecture,executor>> can be re-invoked in StackSaga.
After executing your logic inside the executor, you can provide to the <<SEC,SEC>> what should be done as the next based on your conditions.
IF the executed transaction is failed due to a retry-able exception that executor can be re-invoked.
That helps to have the eventual consistency of the entire transaction.

. IF a <<dual_consistency_problem_of_sec_in_microservice,chunk-data>> file is restored after every-store problem.

IF your application is a large one.
There can be a lot of retryable transactions from each service in the event-store.
Therefore, executing the retryable transactions will be a heavy process due to the bulk.
To overcome this problem, StackSaga shares all the retryable transactions within the available instances in the zone.
The architecture is quite the same as <<execution_chunk_protection_mechanism_with_the_help_of_eureka_service_registry,chunk-data file relocating>>.
To share the transactions within the available instances, StackSaga follows the master and slave architecture.

*How is the master node appointed with the help of Eureka Registry?*

For selecting the master node, StackSaga uses eureka client metadata.
When the instance is started, StackSaga adds the timestamp as a metadata to the Eureka instance Info.
Then all the instances know who is the oldest instance in the zone.
The older instance will be appointed as the master node by itself.

image::stacksaga-unit-test-Transaction-Replay-Architecture-MI.drawio.svg[alt="StackSaga Transaction Replay Architecture",height=300]


* pass:[<span class="rounded-number">1</span>] Master gets the service registry from the eureka cache, and allocates retryable-transactions in the event-store for each available instance.
In the diagram, instance-1 makes the retryable-transactions allocation (you can configure the allocation count) for instance-2, instance-3, and instance-4.

* pass:[<span class="rounded-number">2</span>] After making the allocation for each.
the master notifies to each instance by making http requests.

* pass:[<span class="rounded-number">3</span>]  Then each instance starts the executing the allocated retryable-transactions bulk.

NOTE: Each availability zone has a master node.

After becoming as the master node, the instance has a special responsibility other than the slaves.
Here there is an allocation process by the master for other instances in the zone.

The slaves try to invoke the *allocated* retryable transactions for that particular instance by the master node.
////

