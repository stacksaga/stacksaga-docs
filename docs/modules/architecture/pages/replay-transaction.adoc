= Transaction Replay. [[replay_transaction]]

The Transaction-Replay helps to re-invoke the transaction that stopped due to xref:replay-transaction.adoc#resource-unavailable[resource-unavailable] issues.
It guarantees eventual consistency.

[[resource-unavailable]]
====
*Resource-Unavailable* term in the Microservice Architecture

In a microservice architecture, a *"resource-unavailable"* issue typically refers to a situation where one microservice is unable to access a necessary resource.
This resource could be another microservice, a database, a third-party API, or any other external system or service that the microservice depends on.
====

If a task is failed due to Resource Unavailable, it can be retried most of the time instead of stopping the task with en exception.
Because It is not easy like in a standalone application with a single database.
If one of atomic transactions is failed, other all atomic transactions that have been successfully executed should state back (undo).
Replaying tasks (transactions/operations) helps to have the eventual consistency.

For identifying the operation is a retryable operation or not, it is used xref:framework:non_retryable_executor_exception.adoc[NonRetryableExecutorException] and xref:framework:retryable_executor_exception.adoc[RetryableExecutorException].
If the executor throws and `RetryableExecutorException` the saga engine keep the transaction in the event-store for retrying.

NOTE: Other that the Stacksaga engine also might face for resource-unavailable issues most rarely due to using a database as the event-store.
It's a most important problem when you use a saga orchestration engine with event sourcing.
Stacksaga provides a reliable solution for that too.
That is discussed under the xref:dual_consistency_problem_of_sec_in_microservice.adoc[dual-consistency] problem topic.

== Who is responsible for replaying?

Replaying transactions is a batch process that executes with a scheduler.
To replay the transactions, A schedule is used that you can configure.

In the event-store, there can have transactions that waiting to be replayed, and those transactions are exposed for replaying when the scheduler is triggered.
But as per architecture, who does trigger the scheduler within the running on instances?
Due to the replaying is batch process, it can not be done in parallel by the many instances.
That means all the available instances can't execute at the same time the transactions that are waiting to be replayed.
One service should execute the replaying process.
Instead of using one instance for doing all replaying related, StackSaga uses a hybrid way.

There are 2 types of implementations for retrying transactions in StackSaga.

. Master and Slaves architecture.
. Service-agent and Slaves architecture.

====

IMPORTANT: Sometimes you might think that why can't run the transactions by the own instance of each individual transaction at the same time? +
The short answer is it can't be done due the instances are xref:replay-transaction.adoc#ephemeral[Ephemeral] in nature in the microservice architecture. +
For instance, just imagine there are 10 instances running on, and there are 100 transactions have been stopped temporarily by them due to some network issues.
After a while, the scheduler is triggered for replying the transactions on each instance.
At that moment it can have different instances count due to scaling up or scaling down based on the load.
Just imagine there was instance called "a" that made some retryable transactions before triggering the scheduler at it is might not be running when the scheduler is triggered.
Then the transactions that made by the instance called "a" cannot be run ever.
(Because the instance is identified with a random generated id and the transaction is stored with that instance id when the transaction is initiated).
Then some transactions can be missing.
This is one of the major reasons that replaying cannot involve all available instances at the same time.

====

[[ephemeral]]
====
*Ephemeral* behavior of the instances.

In the context of microservices, ephemeral refers to the principle that a microservice can be created, destroyed, and replenished on-demand on a target easily, quickly, and with no side effects.
====

== Master and Slaves architecture for retrying

This method refers to electing a leader (Master instance) withing the available instances.
For instance, there can have 10 instances in your cluster for *order-service*.
StackSaga framework has to select one of them as the leader for executing the retrying.
This is where the leader-election comes into the picture.

image:stacksaga-diagram-master-slaves-leader-election.drawio.svg[alt="stacksaga diagram master slaves leader election"]

In The above diagram, it has been mentioned 2 regions.
Transactions replaying is done based on the regional metadata.
A leader is appointed for one region.
That means in a region can have only one leader.
If you have deployed applications in many regions, each region will have one leader.

How is the transaction replaying done?
First of all, let's have an understanding what metadata is saved with the transaction in the event store.

All the transactions are saved in the event-store with the following data.

* Instance id: the instance that the transaction was initialized.
* Region: the region that instance was located
* Zone: the zone that instance was located
* serviceName: the name of the service

NOTE: You can see all the above metadata in the dashboard.

Due to keeping the transaction with the region data, the engine can determine which leader should access which transactions.
If the transaction was initiated in region-1 the transaction will be exposed to the region-1's leader.

Electing the leader is done based on your environment.

== Service-Agent and Slaves architecture for retrying

Service agent architecture refers to having a desperate service for doing the replay instead of selecting one of available instances like master and slaves architecture.

image:stacksaga-diagram-agent-slaves-leader-election.drawio.svg[alt="stacksaga diagram agent slaves leader election"]

NOTE: In this way, the retry dependencies shouldn't be added to the applications.
Instead of that, just run the *saga-service-agent* standalone application by mentioning the target service name(s).

Service agent architecture can be used in 2 ways.

. Agent for service

Your system can have multiple servers like order service, delivery service, customer service and so on.
From those services, some of them have Stacksaga implemented on it.
Just imagine the order service and delivery service use Stacksaga.
So then those services should have agents for process replaying.
We can deploy 2 agent services separately called order-service-agent and *delivery-service-agent*.
In this way, the relationship between the service and the agent is one to one.

image:stacksaga-diagram-seperate-agent-leader-election.drawio.svg[alt="stacksaga diagram seperate agent leader election"]

Here you can see the order-service and delivery-service has separate services called *order-service-agent* and *delivery-service-agent*.

. Agent for services

Instead of having separate service agents, it's delayed a single service for many services.
The relationship between the agent and service is *one-to-many*.
One agent can have many services connected ro retrying.

image:stacksaga-diagram-public-agent-leader-election.drawio.svg[alt="stacksaga diagram public agent leader election"]

IMPORTANT: *Agent for services* can be used only if you use a single xref:event_store.adoc[even-store] for the services that are connected to the agent service.
The reason is only one event-store can be configured into the agent service.
For instance, if you want to deploy a single service age for both order-service and delivery-service, both services should use the same event-store.
Refer the xref:event_store.adoc[even-store] to see the ways that you can use event-store.

== Filtering Retryable transactions from the event-store.

You know already that the replay process is done by running schedulers.
When the scheduler is triggered, the master node fetches the transactions that should be retried from the event-store.

When filtering the retryable transactions, the following things are considered.

. Region: The transactions are filtered for the region of the master instance.
. Transaction status: The transaction status should be *reverting* or *processing*
. xref:replay-transaction.adoc#transaction_lifetime[Transaction Lifetime]
. xref:replay-transaction.adoc#transaction_leisure_time[Transaction Leisure time]
. xref:replay-transaction.adoc#transaction_restore_retention_time[Transaction Restore Retention Time]

[[transaction_lifetime]]
== Transaction Lifetime

All the transactions are retried within a specific duration that you configured.
After the time duration that transactions are expired, It ensures not accumulating the transactions that cannot be invoked successfully after invoking many times.

TIP: In the admin dashboard, you can see the expired transactions.
And also after fixing the issue, you can extend the time for exposing to the retrying process again.

In the below, you can see it with diagram.
The transaction is initiated at the first after initialization the transaction can be exposed to the schedulers withing the specific time period.
After the time period, the transaction is not exposed to re-invoking.

image:stacksaga-diagram-transaction-retry-life-time.drawio.svg[alt="stacksaga diagram transaction retry life time"]

[[transaction_leisure_time]]
== Transaction Leisure time

After exposing the transaction to be retried, the transaction is shared to one of available instances immediately to execute.
After the executing by that particular instance, if the transaction is failed again due to a network issues, the transaction can be exposed to the same scheduler nearly. +
There is no point in executing the transaction again and again within a small amount of time while the target service is unavailable. +
You can configure how long time a transaction should be kept at leisure without exposing to the scheduler.
That time is called as Transaction Leisure time.

In the below, you can see it with diagram.
After initiating the transaction, the transaction has been exposed to retrying if the transaction is failed due to resource-unattainable issue.
After exposing the transaction, the transaction is frozen for a while (based on your configuration) as leisure time.
While that time, no one can access the data for retrying.
After the end of that leisure time, the transaction is exposed for replaying if the transaction is still one of running status (processing or reverting).

image:stacksaga-diagram-retry-leisure-time.drawio.svg[alt="stacksaga diagram retry leisure time"]

[[transaction_restore_retention_time]]
== Transaction Restore Retention Time

How long the transaction should be kept waiting to determine whether the transaction unexpectedly crashed.
The value should be in hours.
If there are some transactions in the event-store that have been shared for replaying but even after 12-hours (configured time,) that transaction has not been retried with that token.
This is a very rare case.
For instance, after receiving the transaction for replaying by the one of available instances, the instance goes down due to a power cut without executing the transaction.
But the leader has been updated as the transaction has been shared to an instance for doing replay.
Due to that, the leader doesn't invoke those transactions again until the transaction is updated by the received instance or the `crashedTransactionRestoreRetentionHours` is exceeded.
Before collecting the transactions that should be retried, the leader checks that if there are some transactions that exceed the `crashedTransactionRestoreRetentionHours` time and those transactions update again as to be eligible for retrying.

image:stacksaga-diagram-tx-retry-stucked-retention.drawio.svg[alt="stacksaga diagram tx retry stucked retention"]

*What happens if a transaction is retried after being declared as crashed?*

That means that due to the retention time is exceeded, the engine decides to expose the transaction for retrying.
Then the transaction will be shared to one of the available instances. +
While then that instance which received the transaction for retrying previously (before the latest expose) invokes the transaction accidentally.

Just imagine the instance has been stuck for 10 hours due to memory issues or kind of situation. +
After 10 hours the that transaction will be executed by the instance that was stuck.

Then there are two situations can be happened.

1. The transaction can be still in the replying status (even though exposed many times after the retention time.
2. The transaction already executed successfully.
(By using other instance(s).

In the first scenario, you may think that the transaction can be executed two times.
Because the old instance again has started to execute the collected transaction to the queue.
And the transaction can be in another instance's queue for executing due to the engine exposed the transaction for retrying after exceeding in the retention time.
Even though There is a one-in-a-billion chance of that happening, it is not invoked two times at all.

Because along with every retry notification, a toke is passed when the execution is shared.
The token number is an integer number that increased one by one every time the transaction is exposed for retrying.

In our case, the old instance's queue can have a less number for the retry notification event than the new instance's queue has.
Therefore, the engine will allow only the token that recently issued.
Then the old transaction is rejected executing.
The diagram shows how it works.
Here you can see that only the execution that contains the latest value is executed (the latest token should be the same as the value in the event-store).
Any other executions are rejected.

image:stacksaga-diagram-retry-leisure-time-crash.drawio.svg[alt="stacksaga diagram retry leisure time crash"]

////

The following reasons are caused to Transaction Replay.

. IF the transaction executor was failed with <<NonRetryableExecutorException,NonRetryableExecutorException>>. +
Any <<executor_architecture,executor>> can be re-invoked in StackSaga.
After executing your logic inside the executor, you can provide to the <<SEC,SEC>> what should be done as the next based on your conditions.
IF the executed transaction is failed due to a retry-able exception that executor can be re-invoked.
That helps to have the eventual consistency of the entire transaction.

. IF a <<dual_consistency_problem_of_sec_in_microservice,chunk-data>> file is restored after every-store problem.

IF your application is a large one.
There can be a lot of retryable transactions from each service in the event-store.
Therefore, executing the retryable transactions will be a heavy process due to the bulk.
To overcome this problem, StackSaga shares all the retryable transactions within the available instances in the zone.
The architecture is quite the same as <<execution_chunk_protection_mechanism_with_the_help_of_eureka_service_registry,chunk-data file relocating>>.
To share the transactions within the available instances, StackSaga follows the master and slave architecture.

*How is the master node appointed with the help of Eureka Registry?*

For selecting the master node, StackSaga uses eureka client metadata.
When the instance is started, StackSaga adds the timestamp as a metadata to the Eureka instance Info.
Then all the instances know who is the oldest instance in the zone.
The older instance will be appointed as the master node by itself.

image::stacksaga-unit-test-Transaction-Replay-Architecture-MI.drawio.svg[alt="StackSaga Transaction Replay Architecture",height=300]


* pass:[<span class="rounded-number">1</span>] Master gets the service registry from the eureka cache, and allocates retryable-transactions in the event-store for each available instance.
In the diagram, instance-1 makes the retryable-transactions allocation (you can configure the allocation count) for instance-2, instance-3, and instance-4.

* pass:[<span class="rounded-number">2</span>] After making the allocation for each.
the master notifies to each instance by making http requests.

* pass:[<span class="rounded-number">3</span>]  Then each instance starts the executing the allocated retryable-transactions bulk.

NOTE: Each availability zone has a master node.

After becoming as the master node, the instance has a special responsibility other than the slaves.
Here there is an allocation process by the master for other instances in the zone.

The slaves try to invoke the *allocated* retryable transactions for that particular instance by the master node.
////

