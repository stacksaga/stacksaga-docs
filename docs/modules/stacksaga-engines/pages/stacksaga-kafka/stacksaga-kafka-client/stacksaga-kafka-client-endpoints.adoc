[[stacksaga-kafka-endpoints]]
== Stacksaga Kafka Endpoints

Stacksaga Kafka Endpoints stands for creating topics accordingly Stacksaga engine's form. the endpoint As per the architecture it can be created 3 types of endpoints as fallows,

. *xref:#query-endpoints[]*
. *xref:#command-endpoints[]*
. *xref:#revert-endpoints[]*


// image::stacksaga-kafka/stacksaga-kafka-client/stacksaga-kafka-engine-stacksaga-kafka-endpoints.svg[]

[[query-endpoints]]
=== Query Endpoints

If an execution(atomic execution) doesn't make any state change due to executing that execution those kinds of executions are executed in *Query Endpoints*. due to it doesn't make any changes in the database state, it has no any compensation action to undo. +
these are the topics that define in the in xref:stacksaga-kafka/saga-topic/saga-topic.adoc[] with type of `SagaTopicType.QUERY_DO_ACTION`

- Each Query Endpoint creates one topic in kafka.
** `DO_VALIDATE_USER` (primary execution topic)
** the topic name should be started with `DO_`

image:stacksaga-kafka/stacksaga-kafka-client/stacksaga-kafka-engine-query-endpoint.svg[]

As per the above diagram,

* the orchestrator service(order-service) trigger an event via the xref:stacksaga-kafka/saga-step-manager/saga-event-navigator.adoc[] the topic of `DO_VALIDATE_USER`(the event is triggered by the SEC behind the sense accordingly your navigation in the xref:stacksaga-kafka/saga-step-manager/saga-event-navigator.adoc[]).

==== Query Endpoints -- Keep‑Ordering Mode with In‑memory retries

This example shows that how a custom Query-Endpoint is implemented in xref:Keep-ordering-mode[] and the retrying is done in xref:Keep-Ordering_In-memory-retries[] mode.

[source,java]
----
@Endpoint(eventName = "USER_VALIDATE")//<1>
public class UserValidateEndpoint extends QueryEndpoint { //<2>
    @Override
    @SagaEndpointListener(value = "DO_USER_VALIDATE") //<3>
    public void doProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException{
        try {
            //implement your execution //<4>
        } catch (Exception e) {
            //throws RetryableException Or NonRetryableException based on the exception; //<5>
        }
    }
    @Override //<6>
    public void onDoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when Query execution retrying exhausted.
    }
}
----

<1> Annotate your custom `QueryEndpoint` class with xref:#Endpoint-annotation[`@Endpoint`] and set the `eventName`.
<2> Extend your custom `QueryEndpoint` class from `QueryEndpoint` abstract class.
then you have to override a *required abstract method* called `doProcess(consumerRecord)`.
<3> Annotate the `doProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].
<4> Implement your real execution here (ex: database accessing etc.).
<5> Catch the exception carefully. the error that you throws will determine whether if the execution should be retried or stop processing. +
As you can see in the method signature, you can throw `RetryableException` or `NonRetryableException` based on the exception you have. +
+
IMPORTANT: Classification the exception is the most important part in stacksaga. the unhandled `RuntimeException`s are considered as `NonRetryableException` exceptions. then the engine stops executing and sent a message to the orchestrator-service as there is a primary execution exception. and then it will start compensation process.
<6> If you want to execute something when the execution is failed even after retrying(retrying-exhausted) you can override and use the `onDoProcessExhausted(consumerRecord)`  method to overcome that as a hock.

==== Query Endpoints -- Keep‑Ordering Mode with Topic‑based/Non-Blocking retries

This example shows that how a custom Query-Endpoint is implemented in xref:Keep-ordering-mode[] and the retrying is done in xref:Keep-Ordering_Topic-based[] mode.

[source,java]
----
@Endpoint(eventName = "USER_VALIDATE")//<1>
public class UserValidateEndpoint extends QueryEndpoint { //<2>
    @Override
    @SagaEndpointListener(value = "DO_USER_VALIDATE") //<3>
    @SagaRetryableEndpoint(attempts = "3", backoff = @Backoff(delay = 5000, multiplier = 0.5)) //<7>
    public void doProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException{
        try {
            //implement your execution //<4>
        } catch (Exception e) {
            //throws RetryableException Or NonRetryableException based on the exception; //<5>
        }
    }
    @Override //<6>
    public void onDoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when Query execution retrying exhausted.
    }
}
----

<1> Annotate your custom `QueryEndpoint` class with xref:#Endpoint-annotation[`@Endpoint`] and set the `eventName`.
<2> Extend your custom `QueryEndpoint` class from `QueryEndpoint` abstract class.
then you have to override a *required abstract method* called `doProcess(consumerRecord)`.
<3> Annotate the `doProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].
<4> Implement your real execution here (ex: database accessing etc.).
<5> Catch the exception carefully. the error that you throws will determine whether if the execution should be retried or stop processing. +
As you can see in the method signature, you can throw `RetryableException` or `NonRetryableException` based on the exception you have. +
+
IMPORTANT: Classification the exception is the most important part in stacksaga. the unhandled `RuntimeException`(s) are considered as `NonRetryableException` exceptions. then the engine stops executing and sent a message to the orchestrator-service as there is a primary execution exception. and then it will start compensation process.
<6> If you want to execute something when the execution is failed even after retrying(retrying-exhausted) you can override and use the `onDoProcessExhausted(consumerRecord)`  method to overcome that as a hock.
<7> ##xref:#retryable_endpoint_annotation[@SagaRetryableEndpoint] annotation has been used for enabling xref:Keep-Ordering_Topic-based[] mode.
it avoids xref:Keep-Ordering_In-memory-retries[] and helps to keep consumer thread non-blocking in retrying. xref:#retryable_endpoint_annotation[read more...]
##

==== Query Endpoints -- Async/Parallel Mode with RetryTemplate in-memory retries

This example shows that how a custom Query-Endpoint is implemented in xref:parallel-mode[] and the retrying is done in xref:parallel-mode[RetryTemplate in-memory retries] mode.

[source,java]
----
@Endpoint(eventName = "USER_VALIDATE")//<1>
public class UserValidateEndpoint extends QueryEndpoint { //<2>
    @Override
    @SagaEndpointListener(value = "DO_USER_VALIDATE") //<3>
    public void doProcess(ConsumerRecord<String, SagaPayload> consumerRecord) {
        this.doProcessAsync(consumerRecord); //<4>
    }

    @Override //<5>
    protected void doProcessAsyncInAction(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException {
        try {
            //implement your execution //<6>
        } catch (Exception e) {
            //throws RetryableException Or NonRetryableException based on the exception; //<7>
        }
    }

    @Override //<8>
    public void onDoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when Query execution retrying exhausted.
    }
}
----

<1> Annotate your custom `QueryEndpoint` class with xref:#Endpoint-annotation[`@Endpoint`] and set the `eventName`.
<2> Extend your custom `QueryEndpoint` class from `QueryEndpoint` abstract class.
then you have to override a *required abstract method* called `doProcess(consumerRecord)`.
<3> Annotate the `doProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].
<4> Call the `doProcessAsync(consumerRecord)` method by passing the received `consumerRecord`.
it will handed off the execution to a separate thread pool and internally configure the retry capabilities, and also it sends the response back to the orchestrator-service after executing(success or failed).
it executes the `doProcessAsyncInAction()` to invoke your real code.

<5> #override the `doProcessAsyncInAction()` method due to that method is invoked by the `doProcessAsync()` internally to run your exact business logic.
this is where you should write your exact business logic.# +
+
NOTE: The method is called in different thread from xref:#[thread pool].

<6> #Implement your real execution here (ex: database accessing etc.).#
<7> ## Catch the exception carefully. the error that you throws will determine whether if the execution should be retried or stop processing. +
As you can see in the method signature, you can throw `RetryableException` or `NonRetryableException` based on the exception you have.## +
+
IMPORTANT: Classification the exception is the most important part in stacksaga. the unhandled `RuntimeException`(s) are considered as `NonRetryableException` exceptions. then the engine stops executing and sent a message to the orchestrator-service as there is a primary execution exception. and then it will start compensation process.
<8> If you want to execute something when the execution is failed even after retrying(retrying-exhausted) you can override and use the `onDoProcessExhausted(consumerRecord)`  method to overcome that as a hock.

[[command-endpoints]]
=== Command Endpoints

if an execution(atomic execution) make some state change in the database of the respective service those kinds of executions are executed in *Command Endpoints*. due to the fact that it make some state changes in the database of the respective service, in case of failure, the changes should be restored by invoking compensation reaction.
these are the topics that define in the in xref:stacksaga-kafka/saga-topic/saga-topic.adoc[] with type of `SagaTopicType.COMMAND_DO_ACTION`

- Each Command Endpoint creates two topics in kafka for the primary execution and the compensation execution.
** `DO_MAKE_PAYMENT` (primary execution topic)
*** the topic name should be started with `DO_`
** `UNDO_MAKE_PAYMENT` (compensating execution topic)
*** the topic name should be started with `UNDO_`

image:stacksaga-kafka/stacksaga-kafka-client/stacksaga-kafka-engine-command-endpoint.svg[]

==== Command-Endpoints -- Keep‑Ordering Mode with In‑memory retries

This example shows that how a custom Command-Endpoint is implemented in xref:Keep-ordering-mode[] and the retrying is done in xref:Keep-Ordering_In-memory-retries[] mode.

[source,java]
----
@Endpoint(eventName = "MAKE_PAYMENT")//<1>
public class MakePaymentEndpoint extends CommandEndpoint { //<2>

    @Override
    @SagaEndpointListener("DO_MAKE_PAYMENT") //<3>
    public void doProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException {

        try {
            final ObjectNode aggregatorForUpdate = consumerRecord.value().getAggregatorForUpdate(); //accessing the current aggregator state //<4>
            double amount = aggregatorForUpdate.get("amount").asDouble();
            if (amount == 0) {
                throw NonRetryableException.buildWith(new IllegalStateException("amount must be greater than 0")); //<5>
            }
            aggregatorForUpdate.put("payment_status", "SUCCESS"); //updating the aggregator state //<6>
        } catch (Exception e) { //<7>
            if (retryable) {
                throw RetryableException.buildWith(e);
            } else {
                throw NonRetryableException.buildWith(e);
            }
        }
    }

    @Override //<8>
    protected void onDoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when primary Command execution retrying exhausted.
    }


    @Override
    @SagaEndpointListener("UNDO_MAKE_PAYMENT") //<9>
    public void undoProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException {
        try {
            final JsonNode aggregator = consumerRecord.value().getAggregator();//accessing the last aggregator state //<10>

            final double amount = aggregator.get("amount").asDouble();
            final PrimaryExecutionException primaryExecutionException = consumerRecord.value().getPrimaryExecutionException().orElseThrow(); //accessing the primary execution exception //<11>
            log.debug("amount is going to be deducted from the account {} due to {}", amount, primaryExecutionException.getRealExceptionMessage());

            consumerRecord.value().getHintStore().ifPresent(historyStore -> {
                historyStore.put("payment_status_revert", "SUCCESS"); //updating the historyStore //<12>
            });
        } catch (Exception e) {
            throw RetryableException.buildWith(e); //<13>
        }
    }

    @Override //<14>
    protected void onUndoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when undo(revert/compensation) execution retrying exhausted.
    }
}
----

<1> Annotate your custom `CommandEndpoint` class with xref:#Endpoint-annotation[`@Endpoint`] and set the `eventName`.

<2> Extend your custom `CommandEndpoint` class from `CommandEndpoint` abstract class.
then you have to override two *required abstract methods* called `doProcess(consumerRecord)` and `undoProcess(consumerRecord)`.

<3> Annotate the `doProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].

<4> Accessing the current aggregator state. you can get the current aggregator state from the `SagaPayload` object and also update the aggregator state upon the business logic.

<5> You can throw a `NonRetryableException` if you want to stop the transaction going forward. orchestrator service will be received an error response, and it will start compensation process.

<6> updating the aggregator state

<7> Catch the exception carefully. the error that you throws will determine whether if the execution should be retried or stop processing. +
As you can see in the method signature, you can throw `RetryableException` or `NonRetryableException` based on the exception you have. +
+
IMPORTANT: Classification the exception is the most important part in stacksaga. the unhandled `RuntimeException`(s) are considered as `NonRetryableException` exceptions. then the engine stops executing and sent a message to the orchestrator-service as there is a primary execution exception. and then it will start compensation process.

<8> If you want to execute something when the primary-execution is failed even after retrying(retrying-exhausted) you can override and use the `onDoProcessExhausted(consumerRecord)`  method to overcome that as a hock.

<9> Annotate the `undoProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].

<10> Accessing the last aggregator state(the state that was before primary-exception occurred) to retrieve the aggregator data.

<11> Accessing the primary execution exception.

<12> Updating the HistoryStore for setting the data on compensation process.

<13> throws and exception. in the compensation process, it can not have any `NonRetryableException` or `RuntimeException` due to compensation. it can have only `RetryableException`.
if an exception is thrown except `RetryableException` the transaction will be terminated by stopping compensation process.

<14> If you want to execute something when the revert-execution is failed even after retrying(retrying-exhausted) you can override and use the `onUndoProcessExhausted(consumerRecord)`  method to overcome that as a hock.

==== Command-Endpoints -- Keep‑Ordering Mode with Topic‑based/Non-Blocking retries

This example shows that how a custom Command-Endpoint is implemented in xref:Keep-ordering-mode[] and the retrying is done in xref:Keep-Ordering_Topic-based[] mode.

[source,java]
----
@Endpoint(eventName = "MAKE_PAYMENT")//<1>
public class MakePaymentEndpoint extends CommandEndpoint { //<2>

    @Override
    @SagaEndpointListener("DO_MAKE_PAYMENT") //<3>
    @SagaRetryableEndpoint(attempts = "3", backoff = @Backoff(delay = 5000, multiplier = 0.5))//<15>
    public void doProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException {

        try {
            final ObjectNode aggregatorForUpdate = consumerRecord.value().getAggregatorForUpdate(); //accessing the current aggregator state //<4>
            double amount = aggregatorForUpdate.get("amount").asDouble();
            if (amount == 0) {
                throw NonRetryableException.buildWith(new IllegalStateException("amount must be greater than 0")); //<5>
            }
            aggregatorForUpdate.put("payment_status", "SUCCESS"); //updating the aggregator state //<6>
        } catch (Exception e) { //<7>
            if (retryable) {
                throw RetryableException.buildWith(e);
            } else {
                throw NonRetryableException.buildWith(e);
            }
        }
    }

    @Override //<8>
    protected void onDoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when primary Command execution retrying exhausted.
    }


    @Override
    @SagaEndpointListener("UNDO_MAKE_PAYMENT") //<9>
    @SagaRetryableEndpoint(attempts = "3", backoff = @Backoff(delay = 5000, multiplier = 0.5))//<15>
    public void undoProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException {
        try {
            final JsonNode aggregator = consumerRecord.value().getAggregator();//accessing the last aggregator state //<10>

            final double amount = aggregator.get("amount").asDouble();
            final PrimaryExecutionException primaryExecutionException = consumerRecord.value().getPrimaryExecutionException().orElseThrow(); //accessing the primary execution exception //<11>
            log.debug("amount is going to be deducted from the account {} due to {}", amount, primaryExecutionException.getRealExceptionMessage());

            consumerRecord.value().getHintStore().ifPresent(historyStore -> {
                historyStore.put("payment_status_revert", "SUCCESS"); //updating the historyStore //<12>
            });
        } catch (Exception e) {
            throw RetryableException.buildWith(e); //<13>
        }
    }

    @Override //<14>
    protected void onUndoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when undo(revert/compensation) execution retrying exhausted.
    }
}
----

<1> Annotate your custom `CommandEndpoint` class with xref:#Endpoint-annotation[`@Endpoint`] and set the `eventName`.

<2> Extend your custom `CommandEndpoint` class from `CommandEndpoint` abstract class.
then you have to override two *required abstract methods* called `doProcess(consumerRecord)` and `undoProcess(consumerRecord)`.

<3> Annotate the `doProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].

<4> Accessing the current aggregator state. you can get the current aggregator state from the `SagaPayload` object and also update the aggregator state upon the business logic.

<5> You can throw a `NonRetryableException` if you want to stop the transaction going forward. orchestrator service will be received an error response, and it will start compensation process.

<6> updating the aggregator state

<7> Catch the exception carefully. the error that you throws will determine whether if the execution should be retried or stop processing. +
As you can see in the method signature, you can throw `RetryableException` or `NonRetryableException` based on the exception you have. +
+
IMPORTANT: Classification the exception is the most important part in stacksaga. the unhandled `RuntimeException`(s) are considered as `NonRetryableException` exceptions. then the engine stops executing and sent a message to the orchestrator-service as there is a primary execution exception. and then it will start compensation process.

<8> If you want to execute something when the primary-execution is failed even after retrying(retrying-exhausted) you can override and use the `onDoProcessExhausted(consumerRecord)`  method to overcome that as a hock.

<9> Annotate the `undoProcess(consumerRecord)` with xref:#SagaEndpointListener-annotation[@SagaEndpointListener] annotation to make the method as a `kafka consumer` and provide the topic name as per the stacksaga xref:#topic-name-specifications[].

<10> Accessing the last aggregator state(the state that was before primary-exception occurred) to retrieve the aggregator data.

<11> Accessing the primary execution exception.

<12> Updating the HistoryStore for setting the data on compensation process.

<13> throws and exception. in the compensation process, it can not have any `NonRetryableException` or `RuntimeException` due to compensation. it can have only `RetryableException`.
if an exception is thrown except `RetryableException` the transaction will be terminated by stopping compensation process.

<14> If you want to execute something when the revert-execution is failed even after retrying(retrying-exhausted) you can override and use the `onUndoProcessExhausted(consumerRecord)`  method to overcome that as a hock.

<15> ##xref:#retryable_endpoint_annotation[@SagaRetryableEndpoint] annotation has been used on `doProcess()` method and `undoProcess()` for enabling xref:Keep-Ordering_Topic-based[] mode.
it avoids xref:Keep-Ordering_In-memory-retries[] and helps to keep consumer thread non-blocking in retrying. xref:#retryable_endpoint_annotation[read more...]
##

==== Command-Endpoints -- Async/Parallel Mode with RetryTemplate in-memory retries

This example shows that how a custom Command-Endpoint is implemented in xref:parallel-mode[] and the retrying is done in xref:parallel-mode[RetryTemplate in-memory retries] mode.

[source,java]
----
@Endpoint(eventName = "MAKE_PAYMENT")
public class MakePaymentEndpoint extends CommandEndpoint {

    private static final Logger log = LoggerFactory.getLogger(MakePaymentEndpoint.class);

    @Override
    @SagaEndpointListener("DO_MAKE_PAYMENT")
    public void doProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException {
        this.doProcessAsync(consumerRecord);
    }

    @Override
    protected void doProcessAsyncInAction(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException, NonRetryableException {
        try {
            //TODO: implement the business logic
            final ObjectNode aggregatorForUpdate = consumerRecord.value().getAggregatorForUpdate(); //accessing the current aggregator state
            double amount = aggregatorForUpdate.get("amount").asDouble();
            if (amount == 0) {
                throw NonRetryableException.buildWith(new IllegalStateException("amount must be greater than 0"));
            }
            aggregatorForUpdate.put("payment_status", "SUCCESS"); //updating the aggregator state
        } catch (Exception e) {
            if (retryable) {
                throw RetryableException.buildWith(e);
            } else {
                throw NonRetryableException.buildWith(e);
            }
        }
    }

    @Override
    protected void onDoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when primary Command execution retrying exhausted.
    }

    @Override
    @SagaEndpointListener("UNDO_MAKE_PAYMENT")
    public void undoProcess(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException {
        this.undoProcessAsync(consumerRecord);
    }

    @Override
    protected void undoProcessAsyncInAction(ConsumerRecord<String, SagaPayload> consumerRecord) throws RetryableException {
        try {
            final JsonNode aggregator = consumerRecord.value().getAggregator();//accessing the last aggregator state

            final double amount = aggregator.get("amount").asDouble();
            final PrimaryExecutionException primaryExecutionException = consumerRecord.value().getPrimaryExecutionException().orElseThrow(); //accessing the primary execution exception
            log.debug("amount is going to be deducted from the account {} due to {}", amount, primaryExecutionException.getRealExceptionMessage());

            consumerRecord.value().getHintStore().ifPresent(historyStore -> {
                historyStore.put("payment_status_revert", "SUCCESS"); //updating the historyStore
            });
        } catch (Exception e) {
            throw RetryableException.buildWith(e);
        }
    }

    @Override
    protected void onUndoProcessExhausted(ConsumerRecord<String, SagaPayload> consumerRecord) {
        //do something when undo(revert/compensation) execution retrying exhausted.
    }
}

----

[[revert-endpoints]]
=== Revert Endpoints

in Command Endpoints,there is a compensation execution for revering. in case if you want to add more execution before or after when the compensation execution is done, you can create *Revert Endpoints* to execute those kind of executions.

- Each Revert Endpoint creates one topic in kafka.
** `REVERT_MAKE_PAYMENT_LOG` (sub compensating execution topic)

image:stacksaga-kafka/stacksaga-kafka-client/stacksaga-kafka-engine-revert-endpoints.svg[]

[[Endpoint-annotation]]
== @Endpoint Annotation

`@Endpoint` Annotation is used for annotating the custom saga endpoint classes, and it has been inherited from spring `@Component`.
the annotation has two parameters as follows,

* `value`: the name of the bean in spring. is it not required to be provided.
* `eventName`: The name of the event action. +
For instance, if we create an endpoint for making the payment, the `eventName` name would be `MAKE_PAYMENT`.

[[topic-name-specifications,Topic name specifications]]
IMPORTANT: *_Topic name specifications_* +
Even though the `eventName` can be any name, it would be related to the real endpoint's topic name in kafka. +
for instance, if we set the `eventName` as `MAKE_PAYMENT` for our xref:command-endpoints[], the real topic name for the primary execution's topic name should be `DO_MAKE_PAYMENT` and the revert(compensation) execution's topic name should be `UNDO_MAKE_PAYMENT`. it is validated by the framework when the application is started and if there are not matched, it will throw an exception. +

[[SagaEndpointListener-annotation]]
== @SagaEndpointListener Annotation

`@SagaEndpointListener` is a StackSaga annotation used to designate a method as a Kafka message listener following the StackSaga framework’s conventions and style.
It is an inherited and optimized version of Spring’s `@KafkaListener`, tailored specifically to suit StackSaga’s requirements. +
most of the parameters can be configured as usual from `@KafkaListener`.
but some of requires have been configured internally by the framework like `containerFactory` , `groupId` etc.

IMPORTANT: `Concurrency` and `TopicPartitions` related configurations can be done as you prefer in the same way as in the `@KafkaListener`.

IMPORTANT: `@SagaEndpointListener` does not support batch option like in `@KafkaListener`. there is an alternative approach `@SagaEndpointListener` supports suit StackSaga’s requirements called xref:#parallel-mode[].

[[retryable_endpoint_annotation]]
== @SagaRetryableEndpoint

== Event Listing approaches in Kafka Client

In Stacksaga Kafka client, there are two primary strategies for handling Kafka messages:

* xref:#Keep-ordering-mode[]
* xref:#parallel-mode[]

[[Keep-ordering-mode]]
== Keep‑Ordering Mode (Synchronous)

- *Description:*
** Messages from a partition are processed one by one in the order Kafka delivers them.
** The consumer thread processes the record and only after successful completion acknowledges the offset.

- *Characteristics:*
** ✅ Strict ordering is guaranteed per partition.

** ✅ Failures can trigger retry or pause/resume logic without skipping messages.

** ❌ If processing is slow, the partition is blocked — no further messages will be processed from that partition until the current one completes.

- *Typical Flow:* +
+
----
poll -> process (same thread) -> ack -> next record
----

- *Retrying:* +
Retrying can be done in two ways in *Keep‑Ordering Mode* as follows, *

* xref:#Keep-Ordering_In-memory-retries[]
* xref:#Keep-Ordering_Topic-based[]

=== Retrying In Keep‑Ordering Mode (Synchronous)

[[Keep-Ordering_In-memory-retries]]
==== In‑memory retries

In‑memory retries is a retry strategy in Spring Kafka where failed message processing is automatically re-attempted using an exponential backoff delay between each retry with help of `DefaultErrorHandler` and  `ExponentialBackOffWithMaxRetries`. +
When the listener throws an exception, the consumer seeks back to the same offset and re-fetches the record from Kafka.
The same consumer thread retries the processing after a backoff interval that grows exponentially (e.g., 1s → 2s → 4s → 8s) until either: +
✅ The message is successfully processed, or +
❌ The maximum retry attempts are reached, at which point the message is ignored without delegated to a Dead Letter Topic (DLT).
This approach ensures message ordering is preserved per partition, prevents tight retry loops, and provides a progressive delay mechanism to avoid overwhelming downstream systems while still guaranteeing that transient failures are handled gracefully. +

[[dtl_not_recommended]]
IMPORTANT: In Stacksaga, delegating messages to a Dead Letter Topic (DLT) is not recommended.
The framework already provides built‑in support for handling failed transactions by automatically rescheduling them for asynchronous retrying.
This eliminates the need for immediate‑retry failures to be stored in Kafka again, avoiding unnecessary storage overhead and simplifying recovery logic.

* *✅ Pros*
** Simple to set up (just configure DefaultErrorHandler)
** Doesn’t require extra Kafka topics
** Good for quick, transient errors (e.g. database hiccup)

* *❌ Cons*
** Blocks the partition until retries are done. xref:#partition_level_blocking_during_retries[see more...]
** If the consumer restarts midway, you “lose” the retry delay and it starts over
** All retrying is synchronous → one thread is tied up

[[partition_level_blocking_during_retries]]
*_Partition-Level Blocking During Retries_*

When a message fails and the `DefaultErrorHandler` with `ExponentialBackOffWithMaxRetries` is applied, the consumer seeks back to the same offset and retries the message on the same thread. +
Because Kafka enforces strict ordering within a partition, no subsequent messages from that partition will be processed until the failing message is either successfully handled or exhausts all retry attempts (after which it may be sent to a Dead Letter Topic or discarded). +
This behavior ensures ordering guarantees are never violated, but it also means that messages queued behind the failing record on that partition will wait. +
Messages on other partitions are not affected — if the listener container is configured with multiple concurrent consumer threads, those other partitions continue processing normally while retries occur on the blocked partition.

[[Keep-Ordering_Topic-based]]
==== Topic‑based/Non-Blocking retries

Topic‑based/Non-Blocking retries can be implemented with *`@SagaRetryableEndpoint`* annotation.
it is an inherited version of https://docs.spring.io/spring-kafka/reference/retrytopic/retry-config.html#using-the-retryabletopic-annotation[`@RetryableTopic`]'s, tailored specifically to suit StackSaga’s requirements.

- *How it works?*

* When a listener fails:

** The failed record is published to a new Kafka topic (e.g., orders-saga-retry-1)
** That retry topic has its own backoff delay (controlled by consumer pause or delayed scheduling)
** After the delay, the record is consumed from the retry topic and processed again
** If it fails again, it may move to another retry topic (e.g., orders-saga-retry-2)
* After final retry(exhausted) → send the repose to the root-topic(orchestrator service's main topic of the aggregator)

IMPORTANT: As mentioned xref:#dtl_not_recommended[above], retry-exhausted messages are not delegated to a Dead Letter Topic (DLT) is not supported even if it is a common approach with spring's `@KafkaListener`. instated, the repose is sent to the root topic of the orchestra service's root topic for re-secluding.

- *Key behavior*
* Retries happen asynchronously via Kafka infrastructure.
* The main partition is not blocked — new messages keep flowing.
* You get better durability: retries survive restarts, because retry messages live in Kafka topics.

* *✅ Pros*
** Doesn’t block the original topic partition
** Survives application restarts (retries live in Kafka)
** Ideal for longer backoff or when you don’t want to tie up threads

* *❌ Cons*
** More complex — Spring Kafka creates extra retry topics
** More Kafka storage overhead (messages copied to retry topics)
** Slightly higher latency (messages hop between topics)

[[parallel-mode]]
== Async/Parallel Mode (Order‑Free)

- *Description:*
* Messages are acknowledged immediately in the consumer thread.
* Processing is handed off to a separate xref:stacksaga-kafka/stacksaga-kafka-client/stacksaga-kafka-client-configuration-properties.adoc[`ThreadPoolTaskExecutor`] for parallel execution and xref:stacksaga-kafka/stacksaga-kafka-client/stacksaga-kafka-client-configuration-properties.adoc[`RetryTemplate`] is used for in-memory retrying internally.

- *Characteristics:*

* ✅ Very fast – consumer thread keeps polling new records without waiting.

* ✅ Parallel processing – multiple messages can be processed at the same time.

* ❌ No ordering guarantee – messages may finish out of order.

* ❌ If async processing fails, Kafka won’t retry because the offset has already been committed (requires a custom retry/error handler).

- *Typical Flow:* +
+
----
poll ->  hand off to thread pool -> ack -> consumer continues polling
----

In Stacksaga Kafka system immediate retrying is done from the target service side. that means the orchestra engine doesn't involve for immediate retrying.
Stacksaga Kafka Client provides supports two ways to manage immediate retrying as follows.
